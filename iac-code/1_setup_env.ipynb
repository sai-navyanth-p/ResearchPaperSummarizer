{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the environment\n",
    "\n",
    "In keeping with good DevOps practices, we will deploy our infrastructure - starting with the Kubernetes cluster - using infrastructure-as-code and configuration-as-code principles:\n",
    "\n",
    "-   The process of provisioning and deploying the infrastructure is scalable, because it is heavily automated. It is easy to rebuild the system, without requiring effort or expertise.\n",
    "-   Everything needed to deploy the infrastructure is in version control.\n",
    "-   The infrastructure is immutable - no manual updates or changes.\n",
    "\n",
    "We will use two IaC/CaC tools to prepare our Kubernetes cluster:\n",
    "\n",
    "-   [Terraform](https://www.terraform.io/), which we’ll use to provision the resources on our cloud infrastructure provider. (A popular alternative is [OpenTofu](https://opentofu.org/).)\n",
    "-   [Ansible](https://github.com/ansible/ansible), which we’ll use to configure and deploy Kubernetes, and then to set up the Kubernetes cluster and the services running on it. (A popular alternative is [Salt](https://github.com/saltstack/salt).)\n",
    "\n",
    "both of which are aligned with the principles above.\n",
    "\n",
    "In this notebook, which will run in the Chameleon Jupyter environment, we will install and configure these tools in that environment. This is a *one-time* step that an engineer would ordinarily do just once, on their own computer.\n",
    "\n",
    "> **Note**: This is a Bash notebook, so you will run it with a Bash kernel. You can change the kernel (if needed) by clicking the kernel name in the top right of the Jupyter interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get infrastructure configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following IaC principles, our infrastructure configuration is all in version control! We have organized all of the materials that “describe” the deployment in our “IaC repository”: <https://github.com/teaching-on-testbeds/gourmetgram-iac.git>.\n",
    "\n",
    "This repository has the following structure:\n",
    "\n",
    "    ├── tf\n",
    "    │   └── kvm\n",
    "    ├── ansible\n",
    "    │   ├── general\n",
    "    │   ├── pre_k8s\n",
    "    │   ├── k8s\n",
    "    │   ├── post_k8s\n",
    "    │   └── argocd\n",
    "    ├── k8s\n",
    "    │   ├── platform\n",
    "    │   ├── staging\n",
    "    │   ├── canary\n",
    "    │   └── production\n",
    "    └── workflows\n",
    "\n",
    "-   The `tf` directory includes materials needed for Terraform to provision resources from the cloud provider. This is a “Day 0” setup task.\n",
    "-   The “Day 1” setup task is to install and configure Kubernetes on the resources. We use Ansible, and the materials are in the `ansible` directory in the `pre_k8s`, `k8s` and `post_k8s` subdirectories. (The `general` directory is just for learning.)\n",
    "-   The applications that we will be deployed in Kubernetes are defined in the `k8s` directory:\n",
    "    -   `platform` has all the “accessory” services we need to support our machine learning application. In this example, it has a model registry and the associated database and object store services used by the model registry; more generally “platform” may include experiment tracking, evaluation and monitoring, and other related services.\n",
    "    -   `staging`, `canary`, and `production` are deployments of our GourmetGram application. A new model or application version starts off in `staging`; after some internal tests it may be promoted to `canary` where it is served to some live users; and after further evaluation and monitoring, it may be promoted to `production`.\n",
    "-   We use Ansible to “register” these applications in ArgoCD, using the playbooks in the `ansible/argocd` directory. ArgoCD is a continuous delivery tool for Kubernetes that automatically deploys and updates applications based on the latest version of its manifests.\n",
    "-   From “Day 2” and on, during the lifecycle of the application, we use ArgoCD and Argo Workflows to handle model and application versions, using the pipelines in `workflows`.\n",
    "\n",
    "In the next cell, we get a copy of the [GourmetGram infrastructure repository](https://github.com/teaching-on-testbeds/gourmetgram-iac.git):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/work/researchpapersummarizer-iac'...\n",
      "remote: Enumerating objects: 2140, done.\u001b[K\n",
      "remote: Counting objects: 100% (2140/2140), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1543/1543), done.\u001b[K\n",
      "remote: Total 2140 (delta 243), reused 2136 (delta 239), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (2140/2140), 3.28 MiB | 2.75 MiB/s, done.\n",
      "Resolving deltas: 100% (243/243), done.\n"
     ]
    }
   ],
   "source": [
    "# runs in Chameleon Jupyter environment\n",
    "git clone --recurse-submodules https://github.com/nvklaxmikanth/researchpapersummarizer-iac.git /work/researchpapersummarizer-iac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we use the `--recurse-submodules` argument to `git clone` - we are including Kubespray, an Ansible-based project for deploying Kubernetes, inside our IaC repository as a submodule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the automation and CI/CD tools mentioned above:\n",
    "\n",
    "-   Terraform and Ansible run on the engineer’s own computer, and communicate with the cloud provider/cloud resources over a network.\n",
    "-   ArgoCD and Argo Workflows run on the cloud resources themselves.\n",
    "\n",
    "So, a necessary prerequisite for this workflow is to download, install, and configure Terraform and Ansible on “our own computer” - except in this case, we will use the Chameleon Jupyter environment as “our computer”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and configure Terraform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can use Terraform, we’ll need to download a Terraform client. The following cell will download the Terraform client and “install” it in this environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-05-11 21:42:30--  https://releases.hashicorp.com/terraform/1.10.5/terraform_1.10.5_linux_amd64.zip\n",
      "Resolving releases.hashicorp.com (releases.hashicorp.com)... 18.238.171.54, 18.238.171.62, 18.238.171.101, ...\n",
      "Connecting to releases.hashicorp.com (releases.hashicorp.com)|18.238.171.54|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 27714924 (26M) [application/zip]\n",
      "Saving to: ‘terraform_1.10.5_linux_amd64.zip’\n",
      "\n",
      "terraform_1.10.5_li 100%[===================>]  26.43M  55.6MB/s    in 0.5s    \n",
      "\n",
      "2025-05-11 21:42:30 (55.6 MB/s) - ‘terraform_1.10.5_linux_amd64.zip’ saved [27714924/27714924]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# runs in Chameleon Jupyter environment\n",
    "mkdir -p /work/.local/bin\n",
    "wget https://releases.hashicorp.com/terraform/1.10.5/terraform_1.10.5_linux_amd64.zip\n",
    "unzip -o -q terraform_1.10.5_linux_amd64.zip\n",
    "mv terraform /work/.local/bin\n",
    "rm terraform_1.10.5_linux_amd64.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Terraform client has been installed to: `/work/.local/bin`. In order to run `terraform` commands, we will have to add this directory to our `PATH`, which tells the system where to look for executable files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# runs in Chameleon Jupyter environment\n",
    "export PATH=/work/.local/bin:$PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s make sure we can now run `terraform` commands. The following cell should print usage information for the `terraform` command, since we run it without any subcommands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: terraform [global options] <subcommand> [args]\n",
      "\n",
      "The available commands for execution are listed below.\n",
      "The primary workflow commands are given first, followed by\n",
      "less common or more advanced commands.\n",
      "\n",
      "Main commands:\n",
      "  init          Prepare your working directory for other commands\n",
      "  validate      Check whether the configuration is valid\n",
      "  plan          Show changes required by the current configuration\n",
      "  apply         Create or update infrastructure\n",
      "  destroy       Destroy previously-created infrastructure\n",
      "\n",
      "All other commands:\n",
      "  console       Try Terraform expressions at an interactive command prompt\n",
      "  fmt           Reformat your configuration in the standard style\n",
      "  force-unlock  Release a stuck lock on the current workspace\n",
      "  get           Install or upgrade remote Terraform modules\n",
      "  graph         Generate a Graphviz graph of the steps in an operation\n",
      "  import        Associate existing infrastructure with a Terraform resource\n",
      "  login         Obtain and save credentials for a remote host\n",
      "  logout        Remove locally-stored credentials for a remote host\n",
      "  metadata      Metadata related commands\n",
      "  modules       Show all declared modules in a working directory\n",
      "  output        Show output values from your root module\n",
      "  providers     Show the providers required for this configuration\n",
      "  refresh       Update the state to match remote systems\n",
      "  show          Show the current state or a saved plan\n",
      "  state         Advanced state management\n",
      "  taint         Mark a resource instance as not fully functional\n",
      "  test          Execute integration tests for Terraform modules\n",
      "  untaint       Remove the 'tainted' state from a resource instance\n",
      "  version       Show the current Terraform version\n",
      "  workspace     Workspace management\n",
      "\n",
      "Global options (use these before the subcommand, if any):\n",
      "  -chdir=DIR    Switch to a different working directory before executing the\n",
      "                given subcommand.\n",
      "  -help         Show this help output, or the help for a specified subcommand.\n",
      "  -version      An alias for the \"version\" subcommand.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "127",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "# runs in Chameleon Jupyter environment\n",
    "terraform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terraform works by communicating with a cloud provider (either a commercial cloud, like AWS or GCP, or a private cloud, like an on-premises OpenStack cloud, or a hybrid cloud with both types of resources). We will need to prepare credentials with which it can act on our behalf on the Chameleon OpenStack cloud. This is a one-time procedure.\n",
    "\n",
    "To get credentials, open the Horizon GUI:\n",
    "\n",
    "-   from the Chameleon website\n",
    "-   click “Experiment” \\> “KVM@TACC”\n",
    "-   log in if prompted to do so\n",
    "-   check the project drop-down menu near the top left (which shows e.g. “CHI-XXXXXX”), and make sure the correct project is selected.\n",
    "\n",
    "On the left side, expand the “Identity” section and click on “Application Credentials”. Then, click “Create Application Credential”.\n",
    "\n",
    "-   In the “Name”, field, use “mlops-lab”.\n",
    "-   Set the “Expiration” date and time to the due date of this lab. (Note that this will be in UTC time, not your local time zone.) This ensures that if your credential is leaked (e.g. you accidentially push it to a public Github repository), the damage is mitigated.\n",
    "-   Click “Create Application Credential”.\n",
    "-   Choose “Download clouds.yaml”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `clouds.yaml` file will look something like this (expect with an alphanumeric string in place of `REDACTED_UNIQUE_ID` and `REDACTED_SECRET`):\n",
    "\n",
    "    clouds:\n",
    "      openstack:\n",
    "        auth:\n",
    "          auth_url: https://kvm.tacc.chameleoncloud.org:5000\n",
    "          application_credential_id: \"REDACTED_UNIQUE_ID\"\n",
    "          application_credential_secret: \"REDACTED_SECRET\"\n",
    "        region_name: \"KVM@TACC\"\n",
    "        interface: \"public\"\n",
    "        identity_api_version: 3\n",
    "        auth_type: \"v3applicationcredential\"\n",
    "\n",
    "It lists one or more clouds - in this case, a single cloud named “openstack”, and then for each cloud, specifies how to connect and authenticate to that cloud. In particular, the `application_credential_id` and `application_credential_secret` allow an application like Terraform to interact with the Chameleon cloud on your behalf, without having to use your personal Chameleon login.\n",
    "\n",
    "Then, in our Terraform configuration, we will have a block like\n",
    "\n",
    "    provider \"openstack\" {\n",
    "      cloud = \"openstack\"\n",
    "    }\n",
    "\n",
    "where the value assigned to `cloud` tells Terraform which cloud in the `clouds.yaml` file to authenticate to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One nice feature of Terraform is that we can use it to provision resource on multiple clouds. For example, if we wanted to provision resources on both KVM@TACC and CHI@UC (e.g. the training resources on CHI@UC and everything else on KVM@TACC), we might generate application credentials on both sites, and combine them into a `clouds.yaml` like this:\n",
    "\n",
    "    clouds:\n",
    "      kvm:\n",
    "        auth:\n",
    "          auth_url: https://kvm.tacc.chameleoncloud.org:5000\n",
    "          application_credential_id: \"REDACTED_UNIQUE_ID_KVM\"\n",
    "          application_credential_secret: \"REDACTED_SECRET_KVM\"\n",
    "        region_name: \"KVM@TACC\"\n",
    "        interface: \"public\"\n",
    "        identity_api_version: 3\n",
    "        auth_type: \"v3applicationcredential\"\n",
    "      uc:\n",
    "        auth:\n",
    "          auth_url: https://chi.uc.chameleoncloud.org:5000\n",
    "          application_credential_id: \"REDACTED_UNIQUE_ID_UC\"\n",
    "          application_credential_secret: \"REDACTED_SECRET_UC\"\n",
    "        region_name: \"CHI@UC\"\n",
    "        interface: \"public\"\n",
    "        identity_api_version: 3\n",
    "        auth_type: \"v3applicationcredential\"\n",
    "\n",
    "and then in our Terraform configuration, we could specify which OpenStack cloud to use, e.g.\n",
    "\n",
    "    provider \"openstack\" {\n",
    "      cloud = \"kvm\"\n",
    "    }\n",
    "\n",
    "or\n",
    "\n",
    "    provider \"openstack\" {\n",
    "      cloud = \"uc\"\n",
    "    }\n",
    "\n",
    "For now, since we are just using one cloud, we will leave our `clouds.yaml` as is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the file browser in the Chameleon Jupyter environment, you will see a template `clouds.yaml`. Use the file browser to open it, and paste in the\n",
    "\n",
    "          application_credential_id: \"REDACTED_UNIQUE_ID\"\n",
    "          application_credential_secret: \"REDACTED_SECRET\"\n",
    "\n",
    "lines from the `clouds.yaml` that you just downloaded from the KVM@TACC GUI (so that it has the “real” credentials in it). Save the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terraform will look for the `clouds.yaml` in either `~/.config/openstack` or the directory from which we run `terraform` - we will move it to the latter directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# runs in Chameleon Jupyter environment\n",
    "cp /work/researchpapersummarizer-iac/clouds.yaml /work/researchpapersummarizer-iac/tf/kvm/clouds.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and configure Ansible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we’ll set up Ansible! We will similarly need to get the Ansible client, which we install in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ansible-core==2.16.9 in ./.local/lib/python3.10/site-packages (2.16.9)\n",
      "Requirement already satisfied: ansible==9.8.0 in ./.local/lib/python3.10/site-packages (9.8.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ansible-core==2.16.9) (23.0)\n",
      "Requirement already satisfied: jinja2>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from ansible-core==2.16.9) (3.1.2)\n",
      "Requirement already satisfied: resolvelib<1.1.0,>=0.5.3 in ./.local/lib/python3.10/site-packages (from ansible-core==2.16.9) (1.0.1)\n",
      "Requirement already satisfied: cryptography in /opt/conda/lib/python3.10/site-packages (from ansible-core==2.16.9) (39.0.2)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.10/site-packages (from ansible-core==2.16.9) (5.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=3.0.0->ansible-core==2.16.9) (2.1.2)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography->ansible-core==2.16.9) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography->ansible-core==2.16.9) (2.21)\n"
     ]
    }
   ],
   "source": [
    "# runs in Chameleon Jupyter environment\n",
    "PYTHONUSERBASE=/work/.local pip install --user ansible-core==2.16.9 ansible==9.8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Ansible client has been installed to: `/work/.local/bin`. In order to run `ansible-playbook` commands, we will have to add this directory to our `PATH`, which tells the system where to look for executable files. We also need to let it know where to find the corresponding Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# runs in Chameleon Jupyter environment\n",
    "export PATH=/work/.local/bin:$PATH\n",
    "export PYTHONUSERBASE=/work/.local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s make sure we can now run `ansible-playbook` commands. The following cell should print usage information for the `ansible-playbook` command, since we run it with `--help`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ansible-playbook [-h] [--version] [-v] [--private-key PRIVATE_KEY_FILE]\n",
      "                        [-u REMOTE_USER] [-c CONNECTION] [-T TIMEOUT]\n",
      "                        [--ssh-common-args SSH_COMMON_ARGS]\n",
      "                        [--sftp-extra-args SFTP_EXTRA_ARGS]\n",
      "                        [--scp-extra-args SCP_EXTRA_ARGS]\n",
      "                        [--ssh-extra-args SSH_EXTRA_ARGS]\n",
      "                        [-k | --connection-password-file CONNECTION_PASSWORD_FILE]\n",
      "                        [--force-handlers] [--flush-cache] [-b]\n",
      "                        [--become-method BECOME_METHOD]\n",
      "                        [--become-user BECOME_USER]\n",
      "                        [-K | --become-password-file BECOME_PASSWORD_FILE]\n",
      "                        [-t TAGS] [--skip-tags SKIP_TAGS] [-C] [-D]\n",
      "                        [-i INVENTORY] [--list-hosts] [-l SUBSET]\n",
      "                        [-e EXTRA_VARS] [--vault-id VAULT_IDS]\n",
      "                        [-J | --vault-password-file VAULT_PASSWORD_FILES]\n",
      "                        [-f FORKS] [-M MODULE_PATH] [--syntax-check]\n",
      "                        [--list-tasks] [--list-tags] [--step]\n",
      "                        [--start-at-task START_AT_TASK]\n",
      "                        playbook [playbook ...]\n",
      "\n",
      "Runs Ansible playbooks, executing the defined tasks on the targeted hosts.\n",
      "\n",
      "positional arguments:\n",
      "  playbook              Playbook(s)\n",
      "\n",
      "options:\n",
      "  --become-password-file BECOME_PASSWORD_FILE, --become-pass-file BECOME_PASSWORD_FILE\n",
      "                        Become password file\n",
      "  --connection-password-file CONNECTION_PASSWORD_FILE, --conn-pass-file CONNECTION_PASSWORD_FILE\n",
      "                        Connection password file\n",
      "  --flush-cache         clear the fact cache for every host in inventory\n",
      "  --force-handlers      run handlers even if a task fails\n",
      "  --list-hosts          outputs a list of matching hosts; does not execute\n",
      "                        anything else\n",
      "  --list-tags           list all available tags\n",
      "  --list-tasks          list all tasks that would be executed\n",
      "  --skip-tags SKIP_TAGS\n",
      "                        only run plays and tasks whose tags do not match these\n",
      "                        values. This argument may be specified multiple times.\n",
      "  --start-at-task START_AT_TASK\n",
      "                        start the playbook at the task matching this name\n",
      "  --step                one-step-at-a-time: confirm each task before running\n",
      "  --syntax-check        perform a syntax check on the playbook, but do not\n",
      "                        execute it\n",
      "  --vault-id VAULT_IDS  the vault identity to use. This argument may be\n",
      "                        specified multiple times.\n",
      "  --vault-password-file VAULT_PASSWORD_FILES, --vault-pass-file VAULT_PASSWORD_FILES\n",
      "                        vault password file\n",
      "  --version             show program's version number, config file location,\n",
      "                        configured module search path, module location,\n",
      "                        executable location and exit\n",
      "  -C, --check           don't make any changes; instead, try to predict some\n",
      "                        of the changes that may occur\n",
      "  -D, --diff            when changing (small) files and templates, show the\n",
      "                        differences in those files; works great with --check\n",
      "  -J, --ask-vault-password, --ask-vault-pass\n",
      "                        ask for vault password\n",
      "  -K, --ask-become-pass\n",
      "                        ask for privilege escalation password\n",
      "  -M MODULE_PATH, --module-path MODULE_PATH\n",
      "                        prepend colon-separated path(s) to module library\n",
      "                        (default={{ ANSIBLE_HOME ~\n",
      "                        \"/plugins/modules:/usr/share/ansible/plugins/modules\"\n",
      "                        }}). This argument may be specified multiple times.\n",
      "  -e EXTRA_VARS, --extra-vars EXTRA_VARS\n",
      "                        set additional variables as key=value or YAML/JSON, if\n",
      "                        filename prepend with @. This argument may be\n",
      "                        specified multiple times.\n",
      "  -f FORKS, --forks FORKS\n",
      "                        specify number of parallel processes to use\n",
      "                        (default=5)\n",
      "  -h, --help            show this help message and exit\n",
      "  -i INVENTORY, --inventory INVENTORY, --inventory-file INVENTORY\n",
      "                        specify inventory host path or comma separated host\n",
      "                        list. --inventory-file is deprecated. This argument\n",
      "                        may be specified multiple times.\n",
      "  -k, --ask-pass        ask for connection password\n",
      "  -l SUBSET, --limit SUBSET\n",
      "                        further limit selected hosts to an additional pattern\n",
      "  -t TAGS, --tags TAGS  only run plays and tasks tagged with these values.\n",
      "                        This argument may be specified multiple times.\n",
      "  -v, --verbose         Causes Ansible to print more debug messages. Adding\n",
      "                        multiple -v will increase the verbosity, the builtin\n",
      "                        plugins currently evaluate up to -vvvvvv. A reasonable\n",
      "                        level to start is -vvv, connection debugging might\n",
      "                        require -vvvv. This argument may be specified multiple\n",
      "                        times.\n",
      "\n",
      "Connection Options:\n",
      "  control as whom and how to connect to hosts\n",
      "\n",
      "  --private-key PRIVATE_KEY_FILE, --key-file PRIVATE_KEY_FILE\n",
      "                        use this file to authenticate the connection\n",
      "  --scp-extra-args SCP_EXTRA_ARGS\n",
      "                        specify extra arguments to pass to scp only (e.g. -l)\n",
      "  --sftp-extra-args SFTP_EXTRA_ARGS\n",
      "                        specify extra arguments to pass to sftp only (e.g. -f,\n",
      "                        -l)\n",
      "  --ssh-common-args SSH_COMMON_ARGS\n",
      "                        specify common arguments to pass to sftp/scp/ssh (e.g.\n",
      "                        ProxyCommand)\n",
      "  --ssh-extra-args SSH_EXTRA_ARGS\n",
      "                        specify extra arguments to pass to ssh only (e.g. -R)\n",
      "  -T TIMEOUT, --timeout TIMEOUT\n",
      "                        override the connection timeout in seconds (default\n",
      "                        depends on connection)\n",
      "  -c CONNECTION, --connection CONNECTION\n",
      "                        connection type to use (default=ssh)\n",
      "  -u REMOTE_USER, --user REMOTE_USER\n",
      "                        connect as this user (default=None)\n",
      "\n",
      "Privilege Escalation Options:\n",
      "  control how and which user you become as on target hosts\n",
      "\n",
      "  --become-method BECOME_METHOD\n",
      "                        privilege escalation method to use (default=sudo), use\n",
      "                        `ansible-doc -t become -l` to list valid choices.\n",
      "  --become-user BECOME_USER\n",
      "                        run operations as this user (default=root)\n",
      "  -b, --become          run operations with become (does not imply password\n",
      "                        prompting)\n"
     ]
    }
   ],
   "source": [
    "# runs in Chameleon Jupyter environment\n",
    "ansible-playbook --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we’ll configure Ansible. The `ansible.cfg` configuration file modifies the default behavior of the Ansible commands we’re going to run. Open this file using the file browser on the left side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our configuration will include:\n",
    "\n",
    "    [defaults]\n",
    "    stdout_callback = yaml\n",
    "    inventory = /work/gourmetgram-iac/ansible/inventory.yaml\n",
    "\n",
    "The first line is just a matter of preference, and directs the Ansible client to display output from commands in a more structured, readable way. The second line specifies the location of a default *inventory* file - the list of hosts that Ansible will configure.\n",
    "\n",
    "It will also include:\n",
    "\n",
    "    [ssh_connection]\n",
    "    ssh_args = -o StrictHostKeyChecking=off -o UserKnownHostsFile=/dev/null -o ForwardAgent=yes -o ProxyCommand=\"ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -W %h:%p cc@A.B.C.D\"\n",
    "\n",
    "which says that when Ansible uses SSH to connect to the resources it is managing, it should “jump” through `A.B.C.D` and forward the keys from this environment, through `A.B.C.D`, to the final destination. (Also, we disable host key checking when using SSH.)\n",
    "\n",
    "You will need to edit `A.B.C.D.` *after* you provision your resources, and replace it with the floating IP assigned to your experiment.\n",
    "\n",
    "*After* you have edited the floating IP and saved the `ansible.cfg` file, you can move it - Ansible will look in either `~/.ansible.cfg` or the directory that we run Ansible commands from, we will use the latter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# runs in Chameleon Jupyter environment\n",
    "# ONLY AFTER YOU HAVE PROVISIONED RESOURCES AND UPDATED THE CFG\n",
    "cp /work/researchpapersummarizer-iac/ansible.cfg /work/researchpapersummarizer-iac/ansible/ansible.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Terraform and Ansible executables have been installed to a location that is not the system-wide location for executable files: `/work/.local/bin`. In order to run `terraform` or `ansible-playbook` commands, we will have to add this directory to our `PATH`, which tells the system where to look for executable files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# runs in Chameleon Jupyter environment\n",
    "export PATH=/work/.local/bin:$PATH\n",
    "export PYTHONUSERBASE=/work/.local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and, we’ll have to do that in *each new Bash session*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Kubespray\n",
    "\n",
    "To install Kubernetes, we’ll use Kubespray, which is a set of Ansible playbooks for deploying Kubernetes. We’ll also make sure we have its dependencies now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ansible==9.8.0 in ./.local/lib/python3.10/site-packages (from -r /work/gourmetgram-iac/ansible/k8s/kubespray/requirements.txt (line 1)) (9.8.0)\n",
      "Requirement already satisfied: jmespath==1.0.1 in /opt/conda/lib/python3.10/site-packages (from -r /work/gourmetgram-iac/ansible/k8s/kubespray/requirements.txt (line 3)) (1.0.1)\n",
      "Requirement already satisfied: jsonschema==4.23.0 in ./.local/lib/python3.10/site-packages (from -r /work/gourmetgram-iac/ansible/k8s/kubespray/requirements.txt (line 5)) (4.23.0)\n",
      "Requirement already satisfied: netaddr==1.3.0 in /opt/conda/lib/python3.10/site-packages (from -r /work/gourmetgram-iac/ansible/k8s/kubespray/requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: ansible-core~=2.16.9 in ./.local/lib/python3.10/site-packages (from ansible==9.8.0->-r /work/gourmetgram-iac/ansible/k8s/kubespray/requirements.txt (line 1)) (2.16.9)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.local/lib/python3.10/site-packages (from jsonschema==4.23.0->-r /work/gourmetgram-iac/ansible/k8s/kubespray/requirements.txt (line 5)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.local/lib/python3.10/site-packages (from jsonschema==4.23.0->-r /work/gourmetgram-iac/ansible/k8s/kubespray/requirements.txt (line 5)) (0.24.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema==4.23.0->-r /work/gourmetgram-iac/ansible/k8s/kubespray/requirements.txt (line 5)) (22.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.local/lib/python3.10/site-packages (from jsonschema==4.23.0->-r /work/gourmetgram-iac/ansible/k8s/kubespray/requirements.txt (line 5)) (2025.4.1)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.10/site-packages (from ansible-core~=2.16.9->ansible==9.8.0->-r /work/gourmetgram-iac/ansible/k8s/kubespray/requirements.txt (line 1)) (5.3.1)\n",
      "Requirement already satisfied: resolvelib<1.1.0,>=0.5.3 in ./.local/lib/python3.10/site-packages (from ansible-core~=2.16.9->ansible==9.8.0->-r /work/gourmetgram-iac/ansible/k8s/kubespray/requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: jinja2>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from ansible-core~=2.16.9->ansible==9.8.0->-r /work/gourmetgram-iac/ansible/k8s/kubespray/requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ansible-core~=2.16.9->ansible==9.8.0->-r /work/gourmetgram-iac/ansible/k8s/kubespray/requirements.txt (line 1)) (23.0)\n",
      "Requirement already satisfied: cryptography in /opt/conda/lib/python3.10/site-packages (from ansible-core~=2.16.9->ansible==9.8.0->-r /work/gourmetgram-iac/ansible/k8s/kubespray/requirements.txt (line 1)) (39.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from referencing>=0.28.4->jsonschema==4.23.0->-r /work/gourmetgram-iac/ansible/k8s/kubespray/requirements.txt (line 5)) (4.12.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=3.0.0->ansible-core~=2.16.9->ansible==9.8.0->-r /work/gourmetgram-iac/ansible/k8s/kubespray/requirements.txt (line 1)) (2.1.2)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography->ansible-core~=2.16.9->ansible==9.8.0->-r /work/gourmetgram-iac/ansible/k8s/kubespray/requirements.txt (line 1)) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography->ansible-core~=2.16.9->ansible==9.8.0->-r /work/gourmetgram-iac/ansible/k8s/kubespray/requirements.txt (line 1)) (2.21)\n"
     ]
    }
   ],
   "source": [
    "# runs in Chameleon Jupyter environment\n",
    "PYTHONUSERBASE=/work/.local pip install --user -r /work/gourmetgram-iac/ansible/k8s/kubespray/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
